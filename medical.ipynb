{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waseem9211/sentiment-analysis/blob/master/medical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boGJyucm2s0B",
        "colab_type": "code",
        "outputId": "380d0038-6c4a-4fba-a5d1-4081742dc335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73CXIjuV3nTu",
        "colab_type": "code",
        "outputId": "32e59401-24f8-42a0-b0b5-5ab3d089cfb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df_train=pd.read_csv('/content/train_F3WbcTw.csv')\n",
        "df_test=pd.read_csv('/content/test_tOlRoBf.csv')\n",
        "print(\"Training data size:\",df_train.shape)\n",
        "print(\"Test data size:\",df_test.shape)\n",
        "df_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: (5279, 4)\n",
            "Test data size: (2924, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why youâ€™d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
              "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
              "      <td>fingolimod</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
              "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
              "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "2  fe809672251f6bd0d986e00380f48d047c7e7b76  ...         2\n",
              "3  bd22104dfa9ec80db4099523e03fae7a52735eb6  ...         2\n",
              "4  b227688381f9b25e5b65109dd00f7f895e838249  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlnlev4G2xQR",
        "colab_type": "code",
        "outputId": "eb11c648-c45c-424d-e6d0-a95ddf4be0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_train['sentiment'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3825\n",
              "1     837\n",
              "0     617\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETBRrPcv4fQ6",
        "colab_type": "code",
        "outputId": "ec693686-cb09-416c-9954-09accf898bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train['drug'].value_counts().head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ocrevus        676\n",
              "gilenya        666\n",
              "ocrelizumab    441\n",
              "entyvio        303\n",
              "humira         270\n",
              "fingolimod     238\n",
              "remicade       229\n",
              "opdivo         224\n",
              "tarceva        218\n",
              "cladribine     200\n",
              "Name: drug, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU3j99z9Yim3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D5Z_wwq4jbG",
        "colab_type": "code",
        "outputId": "a8fedb50-c3b7-4908-bea4-0f9135e55a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "BAD_SYMBOLS_RE = re.compile('[^a-zA-Z0-9]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() \n",
        "    text=text.strip()\n",
        "    no_coms=re.sub(r'\\.com','',text)\n",
        "    no_urls=re.sub('https?://www','',no_coms)\n",
        "    no_urls1=re.sub('https?://','',no_urls)     \n",
        "    text = BAD_SYMBOLS_RE.sub(' ', no_urls1) \n",
        "    #text = re.sub('\\d+','',text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "df_test['text'] = df_test['text'].apply(clean_text)\n",
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>autoimmune diseases tend come clusters gilenya...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>completely understand want try results reporte...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
              "      <td>interesting targets s1p 1 5 receptors rather 1...</td>\n",
              "      <td>fingolimod</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
              "      <td>interesting grand merci wonder lemtrada ocrevu...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
              "      <td>hi everybody latest mri results brain cervical...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "2  fe809672251f6bd0d986e00380f48d047c7e7b76  ...         2\n",
              "3  bd22104dfa9ec80db4099523e03fae7a52735eb6  ...         2\n",
              "4  b227688381f9b25e5b65109dd00f7f895e838249  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOcK8GCzgm-Z",
        "colab_type": "code",
        "outputId": "352d5220-99f5-436a-d7cb-3b3b021cc9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df_train['text'].values[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'autoimmune diseases tend come clusters gilenya feel good think change anything waste time energy taking tysabri feel amazing symptoms dodgy color vision since always know know last month year decade ive decided enjoy ride point worrying'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi1BMKIw4na2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MAX_NB_WORDS = 50000  # The maximum number of words to be used. (most frequent)\n",
        "MAX_SEQUENCE_LENGTH = 350\n",
        "EMBEDDING_DIM = 250\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(np.append(df_train[\"text\"].values, df_test[\"text\"].values))\n",
        "word_index = tokenizer.word_index\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXjUUG3Ecq6Q",
        "colab_type": "code",
        "outputId": "fc0a7ca7-e399-4ce9-d642-3dbb78704ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxwords=len(word_index)+1\n",
        "maxwords"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WduE1g_6Cj0",
        "colab_type": "code",
        "outputId": "d9fa1b84-e6de-45f5-9ede-ec81de6683c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train_seq = tokenizer.texts_to_sequences(df_train['text'].values)\n",
        "test_seq = tokenizer.texts_to_sequences(df_test['text'].values)\n",
        "train_seq = pad_sequences(train_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "test_seq = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', train_seq.shape)\n",
        "print('Shape of data tensor:',train_seq[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (5279, 350)\n",
            "Shape of data tensor: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0   950   421  1925   315  8414   124   142    50    96   229\n",
            "   410  4204    18  1040    84   248   142  1575    51 11845  2153   230\n",
            "    79   338    48    48    99   220    45  3193  3376  1044  2379  3519\n",
            "   447  4165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhu9zOI_Fx7q",
        "colab_type": "code",
        "outputId": "2a9ff793-bc9f-45f1-fc0d-1d97e409f4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_state=vectorizer.fit_transform(df_train['drug'])\n",
        "test_state=vectorizer.transform(df_test['drug'])\n",
        "print(train_state.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5279, 110)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsG02uB47e1K",
        "colab_type": "code",
        "outputId": "9dfd4d41-ed42-4e1d-fd09-2558b3debac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y = pd.get_dummies(df_train['sentiment']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (5279, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF38Z30-wTew",
        "colab_type": "code",
        "outputId": "5e461a36-4043-4a43-dc95-efa3e2d79b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_state.shape[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huf6bU10RCTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_model1():\n",
        "    embedding_layer = Embedding(MAX_NB_WORDS,\n",
        "                                300,\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=True)\n",
        "    dropout = SpatialDropout1D(0.2)\n",
        "    mask_layer = Masking()\n",
        "    lstm_layer = LSTM(128,recurrent_dropout=0.2)\n",
        "    seq_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
        "    dense_input = Input(shape=(train_state.shape[1],))\n",
        "    dense_vector = BatchNormalization()(dense_input)\n",
        "    phrase_vector = lstm_layer(mask_layer(dropout(embedding_layer(seq_input))))\n",
        "    feature_vector = concatenate([phrase_vector, dense_vector])\n",
        "    feature_vector = Dense(64, activation=\"relu\")(feature_vector)\n",
        "    output = Dense(3, activation=\"softmax\")(feature_vector)\n",
        "    model = Model(inputs=[seq_input, dense_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "def CNN_model():\n",
        "    CNN_model= Sequential()\n",
        "    CNN_model.add(Embedding(MAX_NB_WORDS,300,input_length=MAX_SEQUENCE_LENGTH))\n",
        "    CNN_model.add(Dropout(0.2))\n",
        "    CNN_model.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
        "    CNN_model.add(GlobalMaxPooling1D())\n",
        "    CNN_model.add(Dense(128,activation='relu'))\n",
        "    CNN_model.add(Dropout(0.2))\n",
        "    CNN_model.add(Dense(3,activation='softmax'))\n",
        "    CNN_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    return CNN_model\n",
        "  \n",
        "def GRU_model():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "  model.add(SpatialDropout1D(0.2))\n",
        "  model.add(Bidirectional(CuDNNGRU(128,)))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_vvK9ngxFun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def split_train_test(data, test_ratio=0.15):\n",
        "  np.random.seed(42)\n",
        "  shuffled_indices = np.random.permutation(data.shape[0])\n",
        "  test_set_size = int((data.shape[0]) * test_ratio)\n",
        "  test_indices = shuffled_indices[:test_set_size]\n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "  return data[train_indices], data[test_indices]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNOaUQyUxFrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_seq, X_val_seq=split_train_test(train_seq)\n",
        "y_train, y_val=split_train_test(Y)\n",
        "X_train_state, X_val_state= split_train_test(train_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvNnAe6QH0Vb",
        "colab_type": "text"
      },
      "source": [
        "**DEEP LEARNING APPROACH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwXZ5FM-xFfQ",
        "colab_type": "code",
        "outputId": "647ccc94-d310-4096-9e00-983c09f5f0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "    model1 = LSTM_model1()\n",
        "    model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
        "    \n",
        "    early_stopping = EarlyStopping(monitor=\"val_acc\", patience=3, verbose=1)\n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model1.fit([X_train_seq, X_train_state], y_train, validation_data=([X_val_seq, X_val_state], y_val),\n",
        "              epochs=10, batch_size=64, callbacks=[early_stopping], verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Training the model...\n",
            "Train on 4488 samples, validate on 791 samples\n",
            "Epoch 1/10\n",
            "4488/4488 [==============================] - 72s 16ms/step - loss: 0.8010 - acc: 0.7068 - val_loss: 0.7853 - val_acc: 0.7155\n",
            "Epoch 2/10\n",
            "4488/4488 [==============================] - 66s 15ms/step - loss: 0.6444 - acc: 0.7442 - val_loss: 0.7812 - val_acc: 0.6966\n",
            "Epoch 3/10\n",
            "4488/4488 [==============================] - 66s 15ms/step - loss: 0.4206 - acc: 0.8425 - val_loss: 0.8798 - val_acc: 0.6852\n",
            "Epoch 4/10\n",
            "4488/4488 [==============================] - 66s 15ms/step - loss: 0.2357 - acc: 0.9249 - val_loss: 1.0231 - val_acc: 0.6523\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd50204d358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9YPlc7UNEfy",
        "colab_type": "code",
        "outputId": "510013f8-01c3-45a1-c2d1-1879b84d9c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "    model2 = CNN_model()\n",
        "    sgd = optimizers.adam(lr=0.001)\n",
        "    model2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "    \n",
        "    early_stopping = EarlyStopping(monitor=\"val_acc\", patience=5, verbose=1)\n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model2.fit(X_train_seq, y_train, validation_data=(X_val_seq, y_val),\n",
        "              epochs=10, batch_size=64, callbacks=[early_stopping], verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Train on 4488 samples, validate on 791 samples\n",
            "Epoch 1/10\n",
            "4488/4488 [==============================] - 5s 1ms/step - loss: 0.8079 - acc: 0.7003 - val_loss: 0.7718 - val_acc: 0.7168\n",
            "Epoch 2/10\n",
            "4488/4488 [==============================] - 3s 561us/step - loss: 0.7147 - acc: 0.7259 - val_loss: 0.7562 - val_acc: 0.7168\n",
            "Epoch 3/10\n",
            "4488/4488 [==============================] - 3s 562us/step - loss: 0.5479 - acc: 0.7636 - val_loss: 0.7631 - val_acc: 0.7105\n",
            "Epoch 4/10\n",
            "4488/4488 [==============================] - 3s 561us/step - loss: 0.2331 - acc: 0.9372 - val_loss: 0.8795 - val_acc: 0.6827\n",
            "Epoch 5/10\n",
            "4488/4488 [==============================] - 3s 561us/step - loss: 0.0744 - acc: 0.9889 - val_loss: 0.9670 - val_acc: 0.6802\n",
            "Epoch 6/10\n",
            "4488/4488 [==============================] - 3s 559us/step - loss: 0.0401 - acc: 0.9953 - val_loss: 1.1591 - val_acc: 0.7042\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4f0c8b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ezihXTPuU-",
        "colab_type": "code",
        "outputId": "2581dc78-7f68-47ad-dac8-51862a5f5581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "    model3 = GRU_model()\n",
        "    model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
        "    \n",
        "    early_stopping = EarlyStopping(monitor=\"val_acc\", patience=3, verbose=1)\n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model3.fit(X_train_seq, y_train, validation_data=(X_val_seq, y_val),\n",
        "              epochs=10, batch_size=8, callbacks=[early_stopping], verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Train on 4488 samples, validate on 791 samples\n",
            "Epoch 1/10\n",
            "4488/4488 [==============================] - 68s 15ms/step - loss: 0.7760 - acc: 0.7248 - val_loss: 0.7742 - val_acc: 0.7130\n",
            "Epoch 2/10\n",
            "4488/4488 [==============================] - 67s 15ms/step - loss: 0.5930 - acc: 0.7674 - val_loss: 0.8766 - val_acc: 0.7004\n",
            "Epoch 3/10\n",
            "4488/4488 [==============================] - 67s 15ms/step - loss: 0.3299 - acc: 0.8817 - val_loss: 0.9904 - val_acc: 0.6473\n",
            "Epoch 4/10\n",
            "4488/4488 [==============================] - 67s 15ms/step - loss: 0.1594 - acc: 0.9485 - val_loss: 1.2296 - val_acc: 0.6435\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4a640aeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHbP8O7ExFcf",
        "colab_type": "code",
        "outputId": "5b37cbcb-b0cf-483f-8f79-f0d248367303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "pred1 = model1.predict([X_val_seq,X_val_state])\n",
        "print('f1_score for {} is: {:0.3f}'.format('lstm',f1_score(np.argmax(y_val,axis=1),np.argmax(pred1,axis=1), average='macro')))\n",
        "pred2 = model2.predict(X_val_seq)\n",
        "print('f1_score for {} is: {:0.3f}'.format('cnn',f1_score(np.argmax(y_val,axis=1),np.argmax(pred2,axis=1), average='macro')))\n",
        "pred3 = model3.predict(X_val_seq)\n",
        "print('f1_score for {} is: {:0.3f}'.format('gru',f1_score(np.argmax(y_val,axis=1),np.argmax(pred3,axis=1), average='macro')))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score for lstm is: 0.440\n",
            "f1_score for cnn is: 0.425\n",
            "f1_score for gru is: 0.413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MsJXKBDH76y",
        "colab_type": "text"
      },
      "source": [
        "**MACHINE LEARNING APPROACH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWmwny_KxFZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRFPNz9xFW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,3),stop_words=\"english\", analyzer='word',max_features=50000)\n",
        "X =vectorizer.fit_transform(df_train['text'])\n",
        "X_test =vectorizer.transform(df_test['text'])\n",
        "Y =df_train['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3dvyVLRKlTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X,Y,test_size=0.15,random_state =0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUQjhUdjxFUF",
        "colab_type": "code",
        "outputId": "c5cae490-8075-4aa1-9b13-558494b318af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "\n",
        "C=np.logspace(-4,2,6)\n",
        "gamma=np.logspace(-4,2,6)\n",
        "pipe=Pipeline([(\"classifier\",RandomForestClassifier())])\n",
        "param_grid=[{\"classifier\":[RandomForestClassifier()],\n",
        "            \"classifier__n_estimators\":[10,100,1000],\n",
        "            \"classifier__max_features\":[1,2,3]},\n",
        "           {\"classifier\":[OneVsRestClassifier(LogisticRegression(class_weight='balanced'))],\n",
        "            \"classifier__estimator__penalty\":['l1','l2'],\n",
        "            \"classifier__estimator__C\":C},\n",
        "           {\"classifier\":[SVC()],\n",
        "            \"classifier__gamma\":gamma,\n",
        "            \"classifier__C\":C},\n",
        "           {\"classifier\":[MultinomialNB()]}]\n",
        "      \n",
        "score=make_scorer(f1_score, average='macro')\n",
        "\n",
        "grid=GridSearchCV(pipe,param_grid,cv=5,verbose=1,n_jobs=-1,scoring=score)\n",
        "grid.fit(X_train,y_train)\n",
        "\n",
        "print('best score',grid.best_score_)\n",
        "print('best param:',grid.best_params_)\n",
        "\n",
        "pred=grid.predict(X_val)\n",
        "print('f1_score on validation set:',f1_score(y_val,pred,average='macro'))\n",
        "print('accuracy on validation set:',accuracy_score(y_val,pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 58 candidates, totalling 290 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done 290 out of 290 | elapsed: 20.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score 0.4873237031593002\n",
            "best param: {'classifier': OneVsRestClassifier(estimator=LogisticRegression(C=0.3981071705534969,\n",
            "                                                 class_weight='balanced',\n",
            "                                                 dual=False, fit_intercept=True,\n",
            "                                                 intercept_scaling=1,\n",
            "                                                 l1_ratio=None, max_iter=100,\n",
            "                                                 multi_class='warn',\n",
            "                                                 n_jobs=None, penalty='l2',\n",
            "                                                 random_state=None,\n",
            "                                                 solver='warn', tol=0.0001,\n",
            "                                                 verbose=0, warm_start=False),\n",
            "                    n_jobs=None), 'classifier__estimator__C': 0.3981071705534969, 'classifier__estimator__penalty': 'l2'}\n",
            "f1_score on validation set: 0.52445536415298\n",
            "accuracy on validation set: 0.6691919191919192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilv-r5Zq3CCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b4954545-f412-4c67-8bf8-b05274f7fe42"
      },
      "source": [
        "test_pred=grid.predict(X_test)\n",
        "df_test[\"sentiment\"]=test_pred.astype('int')\n",
        "df_test['sentiment'].value_counts()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1939\n",
              "1     628\n",
              "0     357\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKzWBzuy9cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=pd.read_csv('/content/test_tOlRoBf.csv')\n",
        "test['sentiment']=df_test['sentiment']\n",
        "test.to_csv('/content/final_test_tOlRoBf.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfC2a8-QkvGz"
      },
      "source": [
        ""
      ]
    }
  ]
}